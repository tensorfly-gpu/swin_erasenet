import paddle


import numpy as np
import logging
import os
import sys
from paddle.distributed import ParallelEnv


def AdjustLearningRate(optimizer, lr):
    for param_group in optimizer.param_groups:
        print('param_group', param_group['lr'])
        param_group['lr'] = lr


def pd_tensor2img(tensor, out_type=np.uint8, min_max=(0, 1)):
    img = tensor.squeeze().cpu().numpy()
    img = img.clip(min_max[0], min_max[1])
    img = (img - min_max[0]) / (min_max[1] - min_max[0])
    if out_type == np.uint8:
        # scaling
        img = img * 255.0
    img = np.transpose(img, (1, 2, 0))
    img = img.round()
    img = img[:, :, ::-1]
    return img.astype(out_type)


# noinspection PyTypeChecker
def setup_logger(output=None, name="ppgan"):
    logger_initialized = []
    """
    Initialize the ppgan logger and set its verbosity level to "INFO".

    Args:
        output (str): a file name or a directory to save log. If None, will not save log file.
            If ends with ".txt" or ".log", assumed to be a file name.
            Otherwise, logs will be saved to `output/log.txt`.
        name (str): the root module name of this logger

    Returns:
        logging.Logger: a logger
    """
    logger = logging.getLogger(name)
    if name in logger_initialized:
        return logger
    logger.setLevel(logging.INFO)
    logger.propagate = False

    plain_formatter = logging.Formatter(
        "[%(asctime)s] %(name)s %(levelname)s: %(message)s",
        datefmt="%m/%d %H:%M:%S")
    # stdout logging: master only
    local_rank = ParallelEnv().local_rank
    if local_rank == 0:
        ch = logging.StreamHandler(stream=sys.stdout)
        ch.setLevel(logging.DEBUG)
        formatter = plain_formatter
        ch.setFormatter(formatter)
        logger.addHandler(ch)

    # file logging: all workers
    if output is not None:
        if output.endswith(".txt") or output.endswith(".log"):
            filename = output
        else:
            filename = os.path.join(output, "log.txt")
        if local_rank > 0:
            filename = filename + ".rank{}".format(local_rank)

        # make dir if path not exist
        os.makedirs(os.path.dirname(filename), exist_ok=True)

        fh = logging.FileHandler(filename, mode='a')
        fh.setLevel(logging.DEBUG)
        fh.setFormatter(plain_formatter)
        logger.addHandler(fh)
    logger_initialized.append(name)
    return logger


def load_pretrained_model(model, pretrained_model):
    if pretrained_model is not None:
        print('Loading pretrained model from {}'.format(pretrained_model))

        if os.path.exists(pretrained_model):
            para_state_dict = paddle.load(pretrained_model)
            model_state_dict = model.state_dict()
            keys = model_state_dict.keys()
            num_params_loaded = 0
            for k in keys:
                if k not in para_state_dict:
                    print('{} is not in pretrained model'.format(k))
                elif list(para_state_dict[k].shape) != list(
                        model_state_dict[k].shape):
                    print("[SKIP] shape of pretrained params {} doesn't match.(Pretrained: {}, Actual:{})"
                          .format(k, para_state_dict[k].shape,
                                  model_state_dict[k].shape))
                else:
                    model_state_dict[k] = para_state_dict[k]
                    num_params_loaded += 1
            model.set_dict(model_state_dict)
            print("There are {}/{} variables loaded into {}."
                  .format(num_params_loaded, len(model_state_dict),
                          model.__class__.__name__))
        else:
            raise ValueError(
                "The pretrained model directory is not Found: {}".format(pretrained_model)
            )
    else:
        print('No pretrained model to load, {} will be trained from scratch.'
              .format(model.__class__.__name__))
